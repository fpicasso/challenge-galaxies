{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":40,"metadata":{"id":"xG2IYVSbkqOt","executionInfo":{"status":"ok","timestamp":1716475857233,"user_tz":-120,"elapsed":460,"user":{"displayName":"Tristan","userId":"15709710985441936674"}}},"outputs":[],"source":["import os\n","import h5py\n","\n","import torch\n","from torch import nn\n","import torchvision\n","from torchvision.transforms import v2\n","\n","import numpy as np\n","import matplotlib.pyplot as plt\n","%matplotlib inline\n","\n"]},{"cell_type":"code","source":["!pip install astronn equinox einops\n","\n","from astroNN.datasets import load_galaxy10\n","from astroNN.datasets.galaxy10 import galaxy10cls_lookup, galaxy10_confusion"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_a-GGZ797h1I","executionInfo":{"status":"ok","timestamp":1716479884453,"user_tz":-120,"elapsed":12455,"user":{"displayName":"Tristan","userId":"15709710985441936674"}},"outputId":"efc0db02-68fb-4bdf-fe3a-94ca6b3a7f8d"},"execution_count":56,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: astronn in /usr/local/lib/python3.10/dist-packages (1.1.0)\n","Requirement already satisfied: equinox in /usr/local/lib/python3.10/dist-packages (0.11.4)\n","Requirement already satisfied: einops in /usr/local/lib/python3.10/dist-packages (0.8.0)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from astronn) (1.25.2)\n","Requirement already satisfied: astropy in /usr/local/lib/python3.10/dist-packages (from astronn) (5.3.4)\n","Requirement already satisfied: h5py in /usr/local/lib/python3.10/dist-packages (from astronn) (3.9.0)\n","Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from astronn) (3.7.1)\n","Requirement already satisfied: astroquery in /usr/local/lib/python3.10/dist-packages (from astronn) (0.4.7)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from astronn) (2.0.3)\n","Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from astronn) (1.2.2)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from astronn) (4.66.4)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from astronn) (24.0)\n","Requirement already satisfied: tensorflow>=2.11.0 in /usr/local/lib/python3.10/dist-packages (from astronn) (2.15.0)\n","Requirement already satisfied: tensorflow-probability>=0.19.0 in /usr/local/lib/python3.10/dist-packages (from astronn) (0.23.0)\n","Requirement already satisfied: jax>=0.4.13 in /usr/local/lib/python3.10/dist-packages (from equinox) (0.4.26)\n","Requirement already satisfied: jaxtyping>=0.2.20 in /usr/local/lib/python3.10/dist-packages (from equinox) (0.2.28)\n","Requirement already satisfied: typing-extensions>=4.5.0 in /usr/local/lib/python3.10/dist-packages (from equinox) (4.11.0)\n","Requirement already satisfied: ml-dtypes>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from jax>=0.4.13->equinox) (0.2.0)\n","Requirement already satisfied: opt-einsum in /usr/local/lib/python3.10/dist-packages (from jax>=0.4.13->equinox) (3.3.0)\n","Requirement already satisfied: scipy>=1.9 in /usr/local/lib/python3.10/dist-packages (from jax>=0.4.13->equinox) (1.11.4)\n","Requirement already satisfied: typeguard==2.13.3 in /usr/local/lib/python3.10/dist-packages (from jaxtyping>=0.2.20->equinox) (2.13.3)\n","Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.11.0->astronn) (1.4.0)\n","Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.11.0->astronn) (1.6.3)\n","Requirement already satisfied: flatbuffers>=23.5.26 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.11.0->astronn) (24.3.25)\n","Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.11.0->astronn) (0.5.4)\n","Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.11.0->astronn) (0.2.0)\n","Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.11.0->astronn) (18.1.1)\n","Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.11.0->astronn) (3.20.3)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.11.0->astronn) (67.7.2)\n","Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.11.0->astronn) (1.16.0)\n","Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.11.0->astronn) (2.4.0)\n","Requirement already satisfied: wrapt<1.15,>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.11.0->astronn) (1.14.1)\n","Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.11.0->astronn) (0.37.0)\n","Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.11.0->astronn) (1.63.0)\n","Requirement already satisfied: tensorboard<2.16,>=2.15 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.11.0->astronn) (2.15.2)\n","Requirement already satisfied: tensorflow-estimator<2.16,>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.11.0->astronn) (2.15.0)\n","Requirement already satisfied: keras<2.16,>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.11.0->astronn) (2.15.0)\n","Requirement already satisfied: decorator in /usr/local/lib/python3.10/dist-packages (from tensorflow-probability>=0.19.0->astronn) (4.4.2)\n","Requirement already satisfied: cloudpickle>=1.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow-probability>=0.19.0->astronn) (2.2.1)\n","Requirement already satisfied: dm-tree in /usr/local/lib/python3.10/dist-packages (from tensorflow-probability>=0.19.0->astronn) (0.1.8)\n","Requirement already satisfied: pyerfa>=2.0 in /usr/local/lib/python3.10/dist-packages (from astropy->astronn) (2.0.1.4)\n","Requirement already satisfied: PyYAML>=3.13 in /usr/local/lib/python3.10/dist-packages (from astropy->astronn) (6.0.1)\n","Requirement already satisfied: requests>=2.19 in /usr/local/lib/python3.10/dist-packages (from astroquery->astronn) (2.31.0)\n","Requirement already satisfied: beautifulsoup4>=4.8 in /usr/local/lib/python3.10/dist-packages (from astroquery->astronn) (4.12.3)\n","Requirement already satisfied: html5lib>=0.999 in /usr/local/lib/python3.10/dist-packages (from astroquery->astronn) (1.1)\n","Requirement already satisfied: keyring>=15.0 in /usr/lib/python3/dist-packages (from astroquery->astronn) (23.5.0)\n","Requirement already satisfied: pyvo>=1.1 in /usr/local/lib/python3.10/dist-packages (from astroquery->astronn) (1.5.2)\n","Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->astronn) (1.2.1)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->astronn) (0.12.1)\n","Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->astronn) (4.51.0)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->astronn) (1.4.5)\n","Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->astronn) (9.4.0)\n","Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->astronn) (3.1.2)\n","Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->astronn) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->astronn) (2023.4)\n","Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas->astronn) (2024.1)\n","Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->astronn) (1.4.2)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->astronn) (3.5.0)\n","Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow>=2.11.0->astronn) (0.43.0)\n","Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4>=4.8->astroquery->astronn) (2.5)\n","Requirement already satisfied: webencodings in /usr/local/lib/python3.10/dist-packages (from html5lib>=0.999->astroquery->astronn) (0.5.1)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19->astroquery->astronn) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19->astroquery->astronn) (3.7)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19->astroquery->astronn) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19->astroquery->astronn) (2024.2.2)\n","Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow>=2.11.0->astronn) (2.27.0)\n","Requirement already satisfied: google-auth-oauthlib<2,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow>=2.11.0->astronn) (1.2.0)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow>=2.11.0->astronn) (3.6)\n","Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow>=2.11.0->astronn) (0.7.2)\n","Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow>=2.11.0->astronn) (3.0.3)\n","Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow>=2.11.0->astronn) (5.3.3)\n","Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow>=2.11.0->astronn) (0.4.0)\n","Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow>=2.11.0->astronn) (4.9)\n","Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow>=2.11.0->astronn) (1.3.1)\n","Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.16,>=2.15->tensorflow>=2.11.0->astronn) (2.1.5)\n","Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow>=2.11.0->astronn) (0.6.0)\n","Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow>=2.11.0->astronn) (3.2.2)\n"]}]},{"cell_type":"code","source":["# Just to make the session somewhat determinate\n","def set_seed(seed):\n","    np.random.seed(seed)\n","    torch.manual_seed(seed)\n","    if torch.cuda.is_available():\n","        torch.cuda.manual_seed(seed)\n","        torch.cuda.manual_seed_all(seed)\n","set_seed(0)"],"metadata":{"id":"X9xx2m1Ho85u"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(f\"CUDA is available: {torch.cuda.is_available()}\")\n","\n","if not torch.cuda.is_available():\n","    print(\"If you want, you might want to switch to a GPU-accelerated session!\")\n","    device = torch.device('cpu')\n","else:\n","    device = torch.device('cuda')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"10FaFPFCpBSL","executionInfo":{"status":"ok","timestamp":1716471159239,"user_tz":-120,"elapsed":254,"user":{"displayName":"Tristan","userId":"15709710985441936674"}},"outputId":"4a7228b4-062c-4ba0-8e66-ccdd6e574aba"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["CUDA is available: False\n","If you want, you might want to switch to a GPU-accelerated session!\n"]}]},{"cell_type":"code","source":["# To load images and labels (will download automatically at the first time)\n","# First time downloading location will be ~/.astroNN/datasets/\n","images, labels= load_galaxy10()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6wyvAJpjpiAP","executionInfo":{"status":"ok","timestamp":1716473611759,"user_tz":-120,"elapsed":86588,"user":{"displayName":"Tristan","userId":"15709710985441936674"}},"outputId":"5c63d27c-a201-4b7f-8930-8e19c30849fc"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["/root/.astroNN/datasets/Galaxy10_DECals.h5 was found!\n"]},{"output_type":"execute_result","data":{"text/plain":["array([0, 0, 0, ..., 9, 9, 9], dtype=uint8)"]},"metadata":{},"execution_count":20}]},{"cell_type":"code","source":["useful_images = images[labels == 5]"],"metadata":{"id":"ksyL5fN4wZ0Q"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train_split = 0.6\n","valid_split = 0.2\n","\n","full_dataset = useful_images\n","\n","test_split = 1 - train_split - valid_split\n","\n","train_dataset, valid_dataset, test_dataset = torch.utils.data.random_split(\n","        full_dataset, [train_split, valid_split, test_split]\n",")"],"metadata":{"id":"UDfxTc7PwSEL"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=128, shuffle=True)\n","valid_loader = torch.utils.data.DataLoader(valid_dataset, batch_size=128, shuffle=False)\n","test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=128, shuffle=False)"],"metadata":{"id":"lVwcV0Wk1rUQ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import fastprogress\n","\n","\n","def train(dataloader, optimizer, model, loss_fn, device, master_bar,\n","          transform_common=None, transform_input=None):\n","    \"\"\"Run one training epoch.\n","\n","    Args:\n","        dataloader (DataLoader): Torch DataLoader object to load data\n","        optimizer: Torch optimizer object\n","        model (nn.Module): Torch model to train\n","        loss_fn: Torch loss function\n","        device (torch.device): Torch device to use for training\n","        master_bar (fastprogress.master_bar): Will be iterated over for each\n","            epoch to draw batches and display training progress\n","        transform_common (function): Transform to apply to input and target\n","        transform_input (function): Transform to apply to the input for de-noising.\n","            By default, no transform is carried out\n","\n","    Returns:\n","        float: Mean loss of this epoch\n","    \"\"\"\n","    epoch_loss = []\n","\n","    for x, _ in fastprogress.progress_bar(dataloader, parent=master_bar):\n","        optimizer.zero_grad()\n","        model.train()\n","\n","        x = transform_common(x) if transform_common else x\n","        x_inp = transform_input(x) if transform_input else x\n","\n","        # Forward pass\n","        x = x.to(device)\n","        x_inp = x_inp.to(device)\n","        x_hat, mu, logvar = model(x_inp)\n","\n","        # Compute loss\n","        loss = loss_fn(x_hat, x, mu, logvar)\n","\n","        # Backward pass\n","        loss.backward()\n","        optimizer.step()\n","\n","        # For plotting the train loss, save it for each sample\n","        epoch_loss.append(loss.item())\n","        master_bar.child.comment = f\"Train Loss: {epoch_loss[-1]:.3f}\"\n","\n","    # Return the mean loss and the accuracy of this epoch\n","    return np.mean(epoch_loss)\n","\n","\n","def validate(dataloader, model, loss_fn, device, master_bar,\n","             transform_common=None, transform_input=None):\n","    \"\"\"Compute loss on validation set.\n","\n","    Args:\n","        dataloader (DataLoader): Torch DataLoader object to load data\n","        model (nn.Module): Torch model to train\n","        loss_fn: Torch loss function\n","        device (torch.device): Torch device to use for training\n","        master_bar (fastprogress.master_bar): Will be iterated over to draw\n","            batches and show validation progress\n","        transform_common (function): Transform to apply to input and target\n","        transform_input (function): Transform to apply to the input for de-noising.\n","            By default, no transform is carried out\n","\n","    Returns:\n","        float: Mean loss on validation set\n","    \"\"\"\n","    epoch_loss = []\n","\n","    model.eval()\n","    with torch.no_grad():\n","        for x, _ in fastprogress.progress_bar(dataloader, parent=master_bar):\n","            x = transform_common(x) if transform_common else x\n","\n","            x_inp = transform_input(x) if transform_input else x\n","\n","            # make a prediction on test set\n","            x = x.to(device)\n","            x_inp = x_inp.to(device)\n","            x_hat, mu, logvar = model(x_inp)\n","\n","            # Compute loss\n","            loss = loss_fn(x_hat, x, mu, logvar)\n","\n","            # For plotting the train loss, save it for each sample\n","            epoch_loss.append(loss.item())\n","            master_bar.child.comment = f\"Valid. Loss: {epoch_loss[-1]:.3f}\"\n","\n","    # Return the mean loss, the accuracy and the confusion matrix\n","    return np.mean(epoch_loss)\n","\n","\n","\n","\n","def train_model(model, optimizer, loss_function, device, num_epochs,\n","                train_dataloader, valid_dataloader,\n","                transform_common=None, transform_input=None):\n","    \"\"\"Run model training.\n","\n","    Args:\n","        model (nn.Module): Torch model to train\n","        optimizer: Torch optimizer object\n","        loss_fn: Torch loss function for training\n","        device (torch.device): Torch device to use for training\n","        num_epochs (int): Max. number of epochs to train\n","        train_dataloader (DataLoader): Torch DataLoader object to load the\n","            training data\n","        valid_dataloader (DataLoader): Torch DataLoader object to load the\n","            test data\n","        transform_common (function): Transform to apply to input and target\n","        transform_input (function): Transform to apply to the input for de-noising.\n","            By default, no transform is carried out\n","\n","    Returns:\n","        list, list: Return list of train losses, test losses.\n","    \"\"\"\n","    master_bar = fastprogress.master_bar(range(num_epochs))\n","    epoch_list, train_losses, valid_losses = [], [], []\n","\n","    master_bar.names = [\"Train\", \"Valid.\"]\n","\n","    for epoch in master_bar:\n","        # Train the model\n","        epoch_train_loss = train(train_dataloader, optimizer, model, loss_function, device, master_bar, transform_common, transform_input)\n","        # Validate the model\n","        epoch_valid_loss = validate(valid_dataloader, model, loss_function, device, master_bar, transform_common, transform_input)\n","\n","        # Save loss and acc for plotting\n","        epoch_list.append(epoch + 1)\n","        train_losses.append(epoch_train_loss)\n","        valid_losses.append(epoch_valid_loss)\n","\n","        graphs = [[epoch_list, train_losses], [epoch_list, valid_losses]]\n","        x_bounds = [1, num_epochs]\n","\n","        master_bar.write(\n","            f\"Epoch {epoch + 1}, \"\n","            f\"avg. train loss: {epoch_train_loss:.3f}, \"\n","            f\"avg. valid. loss: {epoch_valid_loss:.3f}\"\n","        )\n","        master_bar.update_graph(graphs, x_bounds)\n","\n","\n","    return train_losses, valid_losses"],"metadata":{"id":"6PLyO5W21kH2","executionInfo":{"status":"ok","timestamp":1716475729425,"user_tz":-120,"elapsed":318,"user":{"displayName":"Tristan","userId":"15709710985441936674"}}},"execution_count":37,"outputs":[]},{"cell_type":"code","source":["class Autoencoder(nn.Module):\n","\n","    def __init__(self, image_size=64,num_channels=3, latent_dims=128, num_filters=32, do_sampling=False):\n","        super(Autoencoder, self).__init__()\n","\n","        self.latent_dims  = latent_dims\n","        self.image_size   = image_size\n","        self.num_channels = num_channels\n","        self.num_filters  = num_filters\n","        self.do_sampling  = do_sampling\n","\n","        # Encoder\n","        self.conv_encoder = nn.Sequential(\n","            # TODO: Build the convolutional layers (torch.nn.Conv2d) here\n","            torch.nn.Conv2d(self.num_channels, self.num_channels, (4,4), 2, 1),\n","            torch.nn.ReLU(),\n","            torch.nn.Conv2d(self.num_channels,self.num_channels, (4,4), 2, 1),\n","            torch.nn.ReLU(),\n","            torch.nn.Conv2d(self.num_channels,self.num_channels, (4,4), 2, 1),\n","            torch.nn.ReLU(),\n","        )\n","\n","        # Linear Encoder\n","        # TODO: Match the dimensionality of the first and last layer here!\n","        self.fc_lin_down = nn.Linear(64*self.num_filters, 8 * self.num_filters)\n","        self.fc_mu       = nn.Linear(8 * self.num_filters, self.latent_dims)\n","        self.fc_logvar   = nn.Linear(self.latent_dims, self.latent_dims)\n","        self.fc_z        = nn.Linear(self.latent_dims, 8 * self.num_filters)\n","        self.fc_lin_up   = nn.Linear(8 * self.num_filters, 64*self.num_filters)\n","\n","        # Decoder\n","        self.conv_decoder = nn.Sequential(\n","            # TODO: Implement the reverse of the encoder here using torch.nn.ConvTranspose2d layers\n","            # The last activation here should be a sigmoid to keep the pixel values clipped in [0, 1)\n","            torch.nn.Conv2d(self.num_channels, self.num_channels, (4,4), 2, 1),\n","            torch.nn.ReLU(),\n","            torch.nn.Conv2d(self.num_channels,self.num_channels, (4,4), 2, 1),\n","            torch.nn.ReLU(),\n","            torch.nn.Conv2d(self.num_channels,self.num_channels, (4,4), 2, 1),\n","            nn.Sigmoid(),\n","        )\n","\n","    def encode(self, x):\n","        ''' Encoder: output is (mean, log(variance))'''\n","        x       = self.conv_encoder(x)\n","        # Here, we resize the convolutional output appropriately for a linear layer\n","        # TODO: Fill in the correct dimensionality for the reordering\n","        x       = x.view(-1, self.num_filters * 8 * 8)\n","        x       = self.fc_lin_down(x)\n","        x       = nn.functional.relu(x)\n","        mu      = self.fc_mu(x)\n","        logvar  = self.fc_logvar(x)\n","        return mu, logvar\n","\n","    def sample(self, mu, logvar):\n","        ''' Sample from Gaussian with mean `mu` and SD `sqrt(exp(logvarz))`'''\n","        # Only use the full mean/stddev procedure if we want to later do sampling\n","        # And only reparametrise if we are in training mode\n","        if self.training and self.do_sampling:\n","            std = torch.exp(logvar * 0.5)\n","            eps = torch.randn_like(std)\n","            sample = mu + (eps * std)\n","            return sample\n","        else:\n","            return mu\n","\n","    def decode(self, z):\n","        '''Decoder: produces reconstruction from sample of latent z'''\n","        z = self.fc_z(z)\n","        z = nn.functional.relu(z)\n","        z = self.fc_lin_up(z)\n","        z = nn.functional.relu(z)\n","        # TODO: Fill in the correct dimensionality for the reordering here again\n","        z = z.view(-1, self.num_filters, 8, 8)\n","        z = self.conv_decoder(z)\n","        return z\n","\n","    def forward(self, x):\n","        mu, logvar = self.encode(x)\n","        z = self.sample(mu, logvar)\n","        x_hat = self.decode(z)\n","        if self.do_sampling:\n","            return x_hat, mu, logvar\n","        else:\n","            return x_hat, None, None"],"metadata":{"id":"7djBzm896ATK","executionInfo":{"status":"ok","timestamp":1716477392543,"user_tz":-120,"elapsed":3,"user":{"displayName":"Tristan","userId":"15709710985441936674"}}},"execution_count":52,"outputs":[]},{"cell_type":"code","source":["def autoencoder_loss(recon_x, x, mu=None, logvar=None):\n","    mse_loss = torch.nn.functional.mse_loss(recon_x, x, reduction='sum') / x.size(dim=0)\n","\n","    if mu is not None and logvar is not None:\n","        raise NotImplementedError(\"Looks like you still need to implement the KL divergence loss!\")\n","    else:\n","        return mse_loss"],"metadata":{"id":"QTZOfcLu_bR1","executionInfo":{"status":"ok","timestamp":1716477394985,"user_tz":-120,"elapsed":272,"user":{"displayName":"Tristan","userId":"15709710985441936674"}}},"execution_count":53,"outputs":[]},{"cell_type":"code","source":["model = Autoencoder()\n","model = model.to(device)\n"],"metadata":{"id":"B1AVTs0f_gFv","executionInfo":{"status":"ok","timestamp":1716477397033,"user_tz":-120,"elapsed":259,"user":{"displayName":"Tristan","userId":"15709710985441936674"}}},"execution_count":54,"outputs":[]},{"cell_type":"code","source":["model"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"VJVZD4r7AAOl","executionInfo":{"status":"ok","timestamp":1716477399005,"user_tz":-120,"elapsed":284,"user":{"displayName":"Tristan","userId":"15709710985441936674"}},"outputId":"d185d5b4-5a78-4c14-b226-f3bd69be8725"},"execution_count":55,"outputs":[{"output_type":"execute_result","data":{"text/plain":["Autoencoder(\n","  (conv_encoder): Sequential(\n","    (0): Conv2d(3, 3, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n","    (1): ReLU()\n","    (2): Conv2d(3, 3, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n","    (3): ReLU()\n","    (4): Conv2d(3, 3, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n","    (5): ReLU()\n","  )\n","  (fc_lin_down): Linear(in_features=2048, out_features=256, bias=True)\n","  (fc_mu): Linear(in_features=256, out_features=128, bias=True)\n","  (fc_logvar): Linear(in_features=128, out_features=128, bias=True)\n","  (fc_z): Linear(in_features=128, out_features=256, bias=True)\n","  (fc_lin_up): Linear(in_features=256, out_features=2048, bias=True)\n","  (conv_decoder): Sequential(\n","    (0): Conv2d(3, 3, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n","    (1): ReLU()\n","    (2): Conv2d(3, 3, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n","    (3): ReLU()\n","    (4): Conv2d(3, 3, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n","    (5): Sigmoid()\n","  )\n",")"]},"metadata":{},"execution_count":55}]}]}