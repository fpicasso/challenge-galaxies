{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "executionInfo": {
     "elapsed": 460,
     "status": "ok",
     "timestamp": 1716475857233,
     "user": {
      "displayName": "Tristan",
      "userId": "15709710985441936674"
     },
     "user_tz": -120
    },
    "id": "xG2IYVSbkqOt"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'torch'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-5490b5e03d2c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mh5py\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorchvision\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'torch'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import h5py\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "import torchvision\n",
    "from torchvision.transforms import v2\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 12455,
     "status": "ok",
     "timestamp": 1716479884453,
     "user": {
      "displayName": "Tristan",
      "userId": "15709710985441936674"
     },
     "user_tz": -120
    },
    "id": "_a-GGZ797h1I",
    "outputId": "efc0db02-68fb-4bdf-fe3a-94ca6b3a7f8d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting astronn\n",
      "  Downloading astroNN-1.1.0-py3-none-any.whl (9.3 MB)\n",
      "\u001b[K     |████████████████████████████████| 9.3 MB 3.5 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting equinox\n",
      "  Downloading equinox-0.10.4-py3-none-any.whl (119 kB)\n",
      "\u001b[K     |████████████████████████████████| 119 kB 21.7 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting einops\n",
      "  Downloading einops-0.8.0-py3-none-any.whl (43 kB)\n",
      "\u001b[K     |████████████████████████████████| 43 kB 2.5 MB/s  eta 0:00:01\n",
      "\u001b[?25hCollecting tensorflow-probability>=0.19.0\n",
      "  Downloading tensorflow_probability-0.21.0-py2.py3-none-any.whl (6.9 MB)\n",
      "\u001b[K     |████████████████████████████████| 6.9 MB 14.6 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: matplotlib in /home/simon/.local/anaconda3/lib/python3.8/site-packages (from astronn) (3.4.1)\n",
      "Requirement already satisfied: h5py in /home/simon/.local/anaconda3/lib/python3.8/site-packages (from astronn) (3.1.0)\n",
      "Requirement already satisfied: scikit-learn in /home/simon/.local/anaconda3/lib/python3.8/site-packages (from astronn) (0.24.1)\n",
      "Collecting astroquery\n",
      "  Downloading astroquery-0.4.7-py3-none-any.whl (5.3 MB)\n",
      "\u001b[K     |████████████████████████████████| 5.3 MB 12.5 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: numpy in /home/simon/.local/anaconda3/lib/python3.8/site-packages (from astronn) (1.19.2)\n",
      "Requirement already satisfied: pandas in /home/simon/.local/anaconda3/lib/python3.8/site-packages (from astronn) (1.2.4)\n",
      "Collecting tensorflow>=2.11.0\n",
      "  Downloading tensorflow-2.13.1-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (479.6 MB)\n",
      "\u001b[K     |████████████████████████████████| 479.6 MB 41 kB/s  eta 0:00:013\n",
      "\u001b[?25hRequirement already satisfied: astropy in /home/simon/.local/anaconda3/lib/python3.8/site-packages (from astronn) (4.2.1)\n",
      "Requirement already satisfied: tqdm in /home/simon/.local/anaconda3/lib/python3.8/site-packages (from astronn) (4.60.0)\n",
      "Requirement already satisfied: packaging in /home/simon/.local/anaconda3/lib/python3.8/site-packages (from astronn) (20.9)\n",
      "Requirement already satisfied: six>=1.12.0 in /home/simon/.local/anaconda3/lib/python3.8/site-packages (from tensorflow>=2.11.0->astronn) (1.15.0)\n",
      "Collecting gast<=0.4.0,>=0.2.1\n",
      "  Downloading gast-0.4.0-py3-none-any.whl (9.8 kB)\n",
      "Collecting astunparse>=1.6.0\n",
      "  Downloading astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
      "Collecting grpcio<2.0,>=1.24.3\n",
      "  Downloading grpcio-1.64.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.6 MB)\n",
      "\u001b[K     |████████████████████████████████| 5.6 MB 3.2 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting tensorflow-estimator<2.14,>=2.13.0\n",
      "  Downloading tensorflow_estimator-2.13.0-py2.py3-none-any.whl (440 kB)\n",
      "\u001b[K     |████████████████████████████████| 440 kB 6.8 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3\n",
      "  Downloading protobuf-4.25.3-cp37-abi3-manylinux2014_x86_64.whl (294 kB)\n",
      "\u001b[K     |████████████████████████████████| 294 kB 9.2 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: typing-extensions<4.6.0,>=3.6.6 in /home/simon/.local/anaconda3/lib/python3.8/site-packages (from tensorflow>=2.11.0->astronn) (3.7.4.3)\n",
      "Collecting absl-py>=1.0.0\n",
      "  Downloading absl_py-2.1.0-py3-none-any.whl (133 kB)\n",
      "\u001b[K     |████████████████████████████████| 133 kB 29.8 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting google-pasta>=0.1.1\n",
      "  Downloading google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
      "\u001b[K     |████████████████████████████████| 57 kB 7.0 MB/s  eta 0:00:01\n",
      "\u001b[?25hCollecting libclang>=13.0.0\n",
      "  Downloading libclang-18.1.1-py2.py3-none-manylinux2010_x86_64.whl (24.5 MB)\n",
      "\u001b[K     |████████████████████████████████| 24.5 MB 15.1 MB/s eta 0:00:01   |                                | 20 kB 8.2 MB/s eta 0:00:03\n",
      "\u001b[?25hRequirement already satisfied: wrapt>=1.11.0 in /home/simon/.local/anaconda3/lib/python3.8/site-packages (from tensorflow>=2.11.0->astronn) (1.12.1)\n",
      "Collecting termcolor>=1.1.0\n",
      "  Downloading termcolor-2.4.0-py3-none-any.whl (7.7 kB)\n",
      "Collecting tensorboard<2.14,>=2.13\n",
      "  Downloading tensorboard-2.13.0-py3-none-any.whl (5.6 MB)\n",
      "\u001b[K     |████████████████████████████████| 5.6 MB 17.5 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: setuptools in /home/simon/.local/anaconda3/lib/python3.8/site-packages (from tensorflow>=2.11.0->astronn) (52.0.0.post20210125)\n",
      "Collecting tensorflow-io-gcs-filesystem>=0.23.1\n",
      "  Downloading tensorflow_io_gcs_filesystem-0.34.0-cp38-cp38-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (2.4 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.4 MB 16.7 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting opt-einsum>=2.3.2\n",
      "  Downloading opt_einsum-3.3.0-py3-none-any.whl (65 kB)\n",
      "\u001b[K     |████████████████████████████████| 65 kB 5.1 MB/s  eta 0:00:01\n",
      "\u001b[?25hCollecting numpy\n",
      "  Downloading numpy-1.24.3-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.3 MB)\n",
      "\u001b[K     |████████████████████████████████| 17.3 MB 5.0 MB/s eta 0:00:011\n",
      "\u001b[?25hCollecting keras<2.14,>=2.13.1\n",
      "  Downloading keras-2.13.1-py3-none-any.whl (1.7 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.7 MB 6.2 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting flatbuffers>=23.1.21\n",
      "  Downloading flatbuffers-24.3.25-py2.py3-none-any.whl (26 kB)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /home/simon/.local/anaconda3/lib/python3.8/site-packages (from astunparse>=1.6.0->tensorflow>=2.11.0->astronn) (0.36.2)\n",
      "Collecting google-auth<3,>=1.6.3\n",
      "  Downloading google_auth-2.29.0-py2.py3-none-any.whl (189 kB)\n",
      "\u001b[K     |████████████████████████████████| 189 kB 18.9 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting markdown>=2.6.8\n",
      "  Downloading Markdown-3.6-py3-none-any.whl (105 kB)\n",
      "\u001b[K     |████████████████████████████████| 105 kB 27.7 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: requests<3,>=2.21.0 in /home/simon/.local/anaconda3/lib/python3.8/site-packages (from tensorboard<2.14,>=2.13->tensorflow>=2.11.0->astronn) (2.25.1)\n",
      "Collecting tensorboard-data-server<0.8.0,>=0.7.0\n",
      "  Downloading tensorboard_data_server-0.7.2-py3-none-manylinux_2_31_x86_64.whl (6.6 MB)\n",
      "\u001b[K     |████████████████████████████████| 6.6 MB 20.6 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting google-auth-oauthlib<1.1,>=0.5\n",
      "  Downloading google_auth_oauthlib-1.0.0-py2.py3-none-any.whl (18 kB)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /home/simon/.local/anaconda3/lib/python3.8/site-packages (from tensorboard<2.14,>=2.13->tensorflow>=2.11.0->astronn) (1.0.1)\n",
      "Collecting pyasn1-modules>=0.2.1\n",
      "  Downloading pyasn1_modules-0.4.0-py3-none-any.whl (181 kB)\n",
      "\u001b[K     |████████████████████████████████| 181 kB 20.9 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting cachetools<6.0,>=2.0.0\n",
      "  Downloading cachetools-5.3.3-py3-none-any.whl (9.3 kB)\n",
      "Collecting rsa<5,>=3.1.4\n",
      "  Downloading rsa-4.9-py3-none-any.whl (34 kB)\n",
      "Collecting requests-oauthlib>=0.7.0\n",
      "  Downloading requests_oauthlib-2.0.0-py2.py3-none-any.whl (24 kB)\n",
      "Collecting importlib-metadata>=4.4\n",
      "  Downloading importlib_metadata-7.1.0-py3-none-any.whl (24 kB)\n",
      "Requirement already satisfied: zipp>=0.5 in /home/simon/.local/anaconda3/lib/python3.8/site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.14,>=2.13->tensorflow>=2.11.0->astronn) (3.4.1)\n",
      "Collecting pyasn1<0.7.0,>=0.4.6\n",
      "  Downloading pyasn1-0.6.0-py2.py3-none-any.whl (85 kB)\n",
      "\u001b[K     |████████████████████████████████| 85 kB 4.1 MB/s  eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: idna<3,>=2.5 in /home/simon/.local/anaconda3/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow>=2.11.0->astronn) (2.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/simon/.local/anaconda3/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow>=2.11.0->astronn) (2022.6.15)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in /home/simon/.local/anaconda3/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow>=2.11.0->astronn) (4.0.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/simon/.local/anaconda3/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow>=2.11.0->astronn) (1.26.4)\n",
      "Collecting oauthlib>=3.0.0\n",
      "  Downloading oauthlib-3.2.2-py3-none-any.whl (151 kB)\n",
      "\u001b[K     |████████████████████████████████| 151 kB 22.2 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting dm-tree\n",
      "  Downloading dm_tree-0.1.8-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (152 kB)\n",
      "\u001b[K     |████████████████████████████████| 152 kB 12.9 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: cloudpickle>=1.3 in /home/simon/.local/anaconda3/lib/python3.8/site-packages (from tensorflow-probability>=0.19.0->astronn) (1.6.0)\n",
      "Requirement already satisfied: decorator in /home/simon/.local/anaconda3/lib/python3.8/site-packages (from tensorflow-probability>=0.19.0->astronn) (5.0.7)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting jaxtyping>=0.2.15\n",
      "  Downloading jaxtyping-0.2.19-py3-none-any.whl (24 kB)\n",
      "Collecting jax>=0.4.4\n",
      "  Downloading jax-0.4.13.tar.gz (1.3 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.3 MB 9.7 MB/s eta 0:00:01\n",
      "\u001b[?25h  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h    Preparing wheel metadata ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting typing-extensions<4.6.0,>=3.6.6\n",
      "  Downloading typing_extensions-4.5.0-py3-none-any.whl (27 kB)\n",
      "Collecting ml-dtypes>=0.1.0\n",
      "  Downloading ml_dtypes-0.2.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.0 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.0 MB 12.7 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting scipy>=1.7\n",
      "  Downloading scipy-1.10.1-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (34.5 MB)\n",
      "\u001b[K     |████████████████████████████████| 34.5 MB 3.7 MB/s eta 0:00:011\n",
      "\u001b[?25hCollecting typeguard>=2.13.3\n",
      "  Downloading typeguard-4.2.1-py3-none-any.whl (34 kB)\n",
      "  Downloading typeguard-4.2.0-py3-none-any.whl (34 kB)\n",
      "  Downloading typeguard-4.1.5-py3-none-any.whl (34 kB)\n",
      "  Downloading typeguard-4.1.4-py3-none-any.whl (34 kB)\n",
      "  Downloading typeguard-4.1.3-py3-none-any.whl (33 kB)\n",
      "  Downloading typeguard-4.1.2-py3-none-any.whl (33 kB)\n",
      "  Downloading typeguard-4.1.1-py3-none-any.whl (33 kB)\n",
      "  Downloading typeguard-4.1.0-py3-none-any.whl (33 kB)\n",
      "  Downloading typeguard-4.0.1-py3-none-any.whl (33 kB)\n",
      "  Downloading typeguard-4.0.0-py3-none-any.whl (33 kB)\n",
      "Requirement already satisfied: pyerfa in /home/simon/.local/anaconda3/lib/python3.8/site-packages (from astropy->astronn) (1.7.2)\n",
      "Collecting pyvo>=1.1\n",
      "  Downloading pyvo-1.5.2-py3-none-any.whl (910 kB)\n",
      "\u001b[K     |████████████████████████████████| 910 kB 14.7 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: beautifulsoup4>=4.8 in /home/simon/.local/anaconda3/lib/python3.8/site-packages (from astroquery->astronn) (4.9.3)\n",
      "Requirement already satisfied: keyring>=15.0 in /home/simon/.local/anaconda3/lib/python3.8/site-packages (from astroquery->astronn) (23.0.1)\n",
      "Requirement already satisfied: html5lib>=0.999 in /home/simon/.local/anaconda3/lib/python3.8/site-packages (from astroquery->astronn) (1.1)\n",
      "Requirement already satisfied: soupsieve>1.2 in /home/simon/.local/anaconda3/lib/python3.8/site-packages (from beautifulsoup4>=4.8->astroquery->astronn) (2.2.1)\n",
      "Requirement already satisfied: webencodings in /home/simon/.local/anaconda3/lib/python3.8/site-packages (from html5lib>=0.999->astroquery->astronn) (0.5.1)\n",
      "Requirement already satisfied: SecretStorage>=3.2 in /home/simon/.local/anaconda3/lib/python3.8/site-packages (from keyring>=15.0->astroquery->astronn) (3.3.1)\n",
      "Requirement already satisfied: jeepney>=0.4.2 in /home/simon/.local/anaconda3/lib/python3.8/site-packages (from keyring>=15.0->astroquery->astronn) (0.6.0)\n",
      "Requirement already satisfied: cryptography>=2.0 in /home/simon/.local/anaconda3/lib/python3.8/site-packages (from SecretStorage>=3.2->keyring>=15.0->astroquery->astronn) (3.4.7)\n",
      "Requirement already satisfied: cffi>=1.12 in /home/simon/.local/anaconda3/lib/python3.8/site-packages (from cryptography>=2.0->SecretStorage>=3.2->keyring>=15.0->astroquery->astronn) (1.14.5)\n",
      "Requirement already satisfied: pycparser in /home/simon/.local/anaconda3/lib/python3.8/site-packages (from cffi>=1.12->cryptography>=2.0->SecretStorage>=3.2->keyring>=15.0->astroquery->astronn) (2.20)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /home/simon/.local/anaconda3/lib/python3.8/site-packages (from matplotlib->astronn) (2.8.1)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in /home/simon/.local/anaconda3/lib/python3.8/site-packages (from matplotlib->astronn) (2.4.7)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /home/simon/.local/anaconda3/lib/python3.8/site-packages (from matplotlib->astronn) (1.3.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/simon/.local/anaconda3/lib/python3.8/site-packages (from matplotlib->astronn) (0.10.0)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /home/simon/.local/anaconda3/lib/python3.8/site-packages (from matplotlib->astronn) (8.2.0)\n",
      "Requirement already satisfied: pytz>=2017.3 in /home/simon/.local/anaconda3/lib/python3.8/site-packages (from pandas->astronn) (2021.1)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /home/simon/.local/anaconda3/lib/python3.8/site-packages (from scikit-learn->astronn) (2.1.0)\n",
      "Requirement already satisfied: joblib>=0.11 in /home/simon/.local/anaconda3/lib/python3.8/site-packages (from scikit-learn->astronn) (1.0.1)\n",
      "Building wheels for collected packages: jax\n",
      "  Building wheel for jax (PEP 517) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for jax: filename=jax-0.4.13-py3-none-any.whl size=1518704 sha256=c4e28f6d7ffecd08a5450f3f7b5c7f533b9688308ed013f3fe8fda62f9e67392\n",
      "  Stored in directory: /home/simon/.cache/pip/wheels/46/d9/15/d2800d4089dc4c77299ac7513c6aa1036f5491edbd2bf6ba16\n",
      "Successfully built jax\n",
      "Installing collected packages: pyasn1, rsa, pyasn1-modules, oauthlib, numpy, cachetools, requests-oauthlib, importlib-metadata, google-auth, typing-extensions, tensorboard-data-server, protobuf, markdown, grpcio, google-auth-oauthlib, absl-py, typeguard, termcolor, tensorflow-io-gcs-filesystem, tensorflow-estimator, tensorboard, scipy, pyvo, opt-einsum, ml-dtypes, libclang, keras, google-pasta, gast, flatbuffers, dm-tree, astunparse, tensorflow-probability, tensorflow, jaxtyping, jax, astroquery, equinox, einops, astronn\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 1.19.2\n",
      "    Uninstalling numpy-1.19.2:\n",
      "      Successfully uninstalled numpy-1.19.2\n",
      "  Attempting uninstall: importlib-metadata\n",
      "    Found existing installation: importlib-metadata 3.10.1\n",
      "    Uninstalling importlib-metadata-3.10.1:\n",
      "      Successfully uninstalled importlib-metadata-3.10.1\n",
      "  Attempting uninstall: typing-extensions\n",
      "    Found existing installation: typing-extensions 3.7.4.3\n",
      "    Uninstalling typing-extensions-3.7.4.3:\n",
      "      Successfully uninstalled typing-extensions-3.7.4.3\n",
      "  Attempting uninstall: scipy\n",
      "    Found existing installation: scipy 1.6.2\n",
      "    Uninstalling scipy-1.6.2:\n",
      "      Successfully uninstalled scipy-1.6.2\n",
      "Successfully installed absl-py-2.1.0 astronn-1.1.0 astroquery-0.4.7 astunparse-1.6.3 cachetools-5.3.3 dm-tree-0.1.8 einops-0.8.0 equinox-0.10.4 flatbuffers-24.3.25 gast-0.4.0 google-auth-2.29.0 google-auth-oauthlib-1.0.0 google-pasta-0.2.0 grpcio-1.64.0 importlib-metadata-7.1.0 jax-0.4.13 jaxtyping-0.2.19 keras-2.13.1 libclang-18.1.1 markdown-3.6 ml-dtypes-0.2.0 numpy-1.24.3 oauthlib-3.2.2 opt-einsum-3.3.0 protobuf-4.25.3 pyasn1-0.6.0 pyasn1-modules-0.4.0 pyvo-1.5.2 requests-oauthlib-2.0.0 rsa-4.9 scipy-1.10.1 tensorboard-2.13.0 tensorboard-data-server-0.7.2 tensorflow-2.13.1 tensorflow-estimator-2.13.0 tensorflow-io-gcs-filesystem-0.34.0 tensorflow-probability-0.21.0 termcolor-2.4.0 typeguard-4.0.0 typing-extensions-4.5.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/simon/.local/anaconda3/lib/python3.8/site-packages/scipy/__init__.py:143: UserWarning: A NumPy version >=1.19.5 and <1.27.0 is required for this version of SciPy (detected version 1.19.2)\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "module compiled against API version 0xf but this version of numpy is 0xd",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;31mRuntimeError\u001b[0m: module compiled against API version 0xf but this version of numpy is 0xd"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "initialization failed",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;31mImportError\u001b[0m: numpy.core.multiarray failed to import",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mSystemError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;31mSystemError\u001b[0m: <built-in method __contains__ of dict object at 0x71f2498b9440> returned a result with an error set",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-0dd0a05f5210>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msystem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'pip install astronn equinox einops'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mastroNN\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatasets\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mload_galaxy10\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mastroNN\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatasets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgalaxy10\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mgalaxy10cls_lookup\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgalaxy10_confusion\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/anaconda3/lib/python3.8/site-packages/astroNN/datasets/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mastroNN\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatasets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapogee\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mload_apogee_distances\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mload_apogee_rc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mload_apokasc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mastroNN\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatasets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgalaxy10\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mload_data\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mload_galaxy10\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mastroNN\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatasets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgalaxy10sdss\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mload_data\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mload_galaxy10sdss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mastroNN\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatasets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mh5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mH5Loader\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mastroNN\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatasets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxmatch\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mxmatch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/anaconda3/lib/python3.8/site-packages/astroNN/datasets/apogee.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mastroNN\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapogee\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mallstar\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mastroNN\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapogee\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdownloader\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mapogee_distances\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mapogee_rc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mastroNN\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgaia\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmag_to_absmag\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmag_to_fakemag\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mextinction_correction\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mastroquery\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvizier\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mVizier\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/anaconda3/lib/python3.8/site-packages/astroNN/gaia/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mastroNN\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgaia\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdownloader\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0manderson_2017_parallax\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgaiadr2_parallax\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mastroNN\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgaia\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdownloader\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtgas\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgaia_source\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mastroNN\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgaia\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdownloader\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtgas_load\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mastroNN\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgaia\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgaia_shared\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mgaia_default_dr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgaia_env\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m from astroNN.gaia.gaia_shared import (\n",
      "\u001b[0;32m~/.local/anaconda3/lib/python3.8/site-packages/astroNN/gaia/downloader.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mastroNN\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mastroNN\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mastroNN\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgaia\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgaia_shared\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mgaia_env\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgaia_default_dr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mastroNN\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshared\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarnings\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdeprecated\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mastroNN\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshared\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdownloader_tools\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mTqdmUpTo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilehash\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/anaconda3/lib/python3.8/site-packages/astroNN/gaia/gaia_shared.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mastropy\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0munits\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mu\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mastroNN\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mMAGIC_NUMBER\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0mdefault_parallax_unit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mu\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmas\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/anaconda3/lib/python3.8/site-packages/astroNN/config.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mplatform\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mastroNN\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshared\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn_tools\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcpu_fallback\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgpu_memory_manage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mastroNN_CACHE_DIR\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpanduser\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"~\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\".astroNN\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/anaconda3/lib/python3.8/site-packages/astroNN/shared/nn_tools.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mwarnings\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplatform\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mis_built_with_cuda\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/anaconda3/lib/python3.8/site-packages/tensorflow/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtyping\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0m_typing\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtools\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmodule_util\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0m_module_util\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlazy_loader\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mLazyLoader\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0m_LazyLoader\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/anaconda3/lib/python3.8/site-packages/tensorflow/python/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpywrap_tensorflow\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0m_pywrap_tensorflow\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meager\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;31m# pylint: enable=wildcard-import\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/context.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpywrap_tfe\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtf2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclient\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpywrap_tf_session\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meager\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcancellation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meager\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mexecute\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/anaconda3/lib/python3.8/site-packages/tensorflow/python/client/pywrap_tf_session.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;31m# pylint: disable=invalid-import-order,g-bad-import-order, wildcard-import, unused-import\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpywrap_tensorflow\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclient\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pywrap_tf_session\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclient\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pywrap_tf_session\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m_TF_SetTarget\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclient\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pywrap_tf_session\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m_TF_SetConfig\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: initialization failed"
     ]
    }
   ],
   "source": [
    "!pip install astronn equinox einops\n",
    "\n",
    "from astroNN.datasets import load_galaxy10\n",
    "from astroNN.datasets.galaxy10 import galaxy10cls_lookup, galaxy10_confusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "X9xx2m1Ho85u"
   },
   "outputs": [],
   "source": [
    "# Just to make the session somewhat determinate\n",
    "def set_seed(seed):\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed(seed)\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "set_seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 254,
     "status": "ok",
     "timestamp": 1716471159239,
     "user": {
      "displayName": "Tristan",
      "userId": "15709710985441936674"
     },
     "user_tz": -120
    },
    "id": "10FaFPFCpBSL",
    "outputId": "4a7228b4-062c-4ba0-8e66-ccdd6e574aba"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA is available: False\n",
      "If you want, you might want to switch to a GPU-accelerated session!\n"
     ]
    }
   ],
   "source": [
    "print(f\"CUDA is available: {torch.cuda.is_available()}\")\n",
    "\n",
    "if not torch.cuda.is_available():\n",
    "    print(\"If you want, you might want to switch to a GPU-accelerated session!\")\n",
    "    device = torch.device('cpu')\n",
    "else:\n",
    "    device = torch.device('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 86588,
     "status": "ok",
     "timestamp": 1716473611759,
     "user": {
      "displayName": "Tristan",
      "userId": "15709710985441936674"
     },
     "user_tz": -120
    },
    "id": "6wyvAJpjpiAP",
    "outputId": "5c63d27c-a201-4b7f-8930-8e19c30849fc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/root/.astroNN/datasets/Galaxy10_DECals.h5 was found!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 9, 9, 9], dtype=uint8)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# To load images and labels (will download automatically at the first time)\n",
    "# First time downloading location will be ~/.astroNN/datasets/\n",
    "images, labels= load_galaxy10()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ksyL5fN4wZ0Q"
   },
   "outputs": [],
   "source": [
    "useful_images = images[labels == 5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UDfxTc7PwSEL"
   },
   "outputs": [],
   "source": [
    "train_split = 0.6\n",
    "valid_split = 0.2\n",
    "\n",
    "full_dataset = useful_images\n",
    "\n",
    "test_split = 1 - train_split - valid_split\n",
    "\n",
    "train_dataset, valid_dataset, test_dataset = torch.utils.data.random_split(\n",
    "        full_dataset, [train_split, valid_split, test_split]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lVwcV0Wk1rUQ"
   },
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=128, shuffle=True)\n",
    "valid_loader = torch.utils.data.DataLoader(valid_dataset, batch_size=128, shuffle=False)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=128, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "executionInfo": {
     "elapsed": 318,
     "status": "ok",
     "timestamp": 1716475729425,
     "user": {
      "displayName": "Tristan",
      "userId": "15709710985441936674"
     },
     "user_tz": -120
    },
    "id": "6PLyO5W21kH2"
   },
   "outputs": [],
   "source": [
    "import fastprogress\n",
    "\n",
    "\n",
    "def train(dataloader, optimizer, model, loss_fn, device, master_bar,\n",
    "          transform_common=None, transform_input=None):\n",
    "    \"\"\"Run one training epoch.\n",
    "\n",
    "    Args:\n",
    "        dataloader (DataLoader): Torch DataLoader object to load data\n",
    "        optimizer: Torch optimizer object\n",
    "        model (nn.Module): Torch model to train\n",
    "        loss_fn: Torch loss function\n",
    "        device (torch.device): Torch device to use for training\n",
    "        master_bar (fastprogress.master_bar): Will be iterated over for each\n",
    "            epoch to draw batches and display training progress\n",
    "        transform_common (function): Transform to apply to input and target\n",
    "        transform_input (function): Transform to apply to the input for de-noising.\n",
    "            By default, no transform is carried out\n",
    "\n",
    "    Returns:\n",
    "        float: Mean loss of this epoch\n",
    "    \"\"\"\n",
    "    epoch_loss = []\n",
    "\n",
    "    for x, _ in fastprogress.progress_bar(dataloader, parent=master_bar):\n",
    "        optimizer.zero_grad()\n",
    "        model.train()\n",
    "\n",
    "        x = transform_common(x) if transform_common else x\n",
    "        x_inp = transform_input(x) if transform_input else x\n",
    "\n",
    "        # Forward pass\n",
    "        x = x.to(device)\n",
    "        x_inp = x_inp.to(device)\n",
    "        x_hat, mu, logvar = model(x_inp)\n",
    "\n",
    "        # Compute loss\n",
    "        loss = loss_fn(x_hat, x, mu, logvar)\n",
    "\n",
    "        # Backward pass\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # For plotting the train loss, save it for each sample\n",
    "        epoch_loss.append(loss.item())\n",
    "        master_bar.child.comment = f\"Train Loss: {epoch_loss[-1]:.3f}\"\n",
    "\n",
    "    # Return the mean loss and the accuracy of this epoch\n",
    "    return np.mean(epoch_loss)\n",
    "\n",
    "\n",
    "def validate(dataloader, model, loss_fn, device, master_bar,\n",
    "             transform_common=None, transform_input=None):\n",
    "    \"\"\"Compute loss on validation set.\n",
    "\n",
    "    Args:\n",
    "        dataloader (DataLoader): Torch DataLoader object to load data\n",
    "        model (nn.Module): Torch model to train\n",
    "        loss_fn: Torch loss function\n",
    "        device (torch.device): Torch device to use for training\n",
    "        master_bar (fastprogress.master_bar): Will be iterated over to draw\n",
    "            batches and show validation progress\n",
    "        transform_common (function): Transform to apply to input and target\n",
    "        transform_input (function): Transform to apply to the input for de-noising.\n",
    "            By default, no transform is carried out\n",
    "\n",
    "    Returns:\n",
    "        float: Mean loss on validation set\n",
    "    \"\"\"\n",
    "    epoch_loss = []\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for x, _ in fastprogress.progress_bar(dataloader, parent=master_bar):\n",
    "            x = transform_common(x) if transform_common else x\n",
    "\n",
    "            x_inp = transform_input(x) if transform_input else x\n",
    "\n",
    "            # make a prediction on test set\n",
    "            x = x.to(device)\n",
    "            x_inp = x_inp.to(device)\n",
    "            x_hat, mu, logvar = model(x_inp)\n",
    "\n",
    "            # Compute loss\n",
    "            loss = loss_fn(x_hat, x, mu, logvar)\n",
    "\n",
    "            # For plotting the train loss, save it for each sample\n",
    "            epoch_loss.append(loss.item())\n",
    "            master_bar.child.comment = f\"Valid. Loss: {epoch_loss[-1]:.3f}\"\n",
    "\n",
    "    # Return the mean loss, the accuracy and the confusion matrix\n",
    "    return np.mean(epoch_loss)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def train_model(model, optimizer, loss_function, device, num_epochs,\n",
    "                train_dataloader, valid_dataloader,\n",
    "                transform_common=None, transform_input=None):\n",
    "    \"\"\"Run model training.\n",
    "\n",
    "    Args:\n",
    "        model (nn.Module): Torch model to train\n",
    "        optimizer: Torch optimizer object\n",
    "        loss_fn: Torch loss function for training\n",
    "        device (torch.device): Torch device to use for training\n",
    "        num_epochs (int): Max. number of epochs to train\n",
    "        train_dataloader (DataLoader): Torch DataLoader object to load the\n",
    "            training data\n",
    "        valid_dataloader (DataLoader): Torch DataLoader object to load the\n",
    "            test data\n",
    "        transform_common (function): Transform to apply to input and target\n",
    "        transform_input (function): Transform to apply to the input for de-noising.\n",
    "            By default, no transform is carried out\n",
    "\n",
    "    Returns:\n",
    "        list, list: Return list of train losses, test losses.\n",
    "    \"\"\"\n",
    "    master_bar = fastprogress.master_bar(range(num_epochs))\n",
    "    epoch_list, train_losses, valid_losses = [], [], []\n",
    "\n",
    "    master_bar.names = [\"Train\", \"Valid.\"]\n",
    "\n",
    "    for epoch in master_bar:\n",
    "        # Train the model\n",
    "        epoch_train_loss = train(train_dataloader, optimizer, model, loss_function, device, master_bar, transform_common, transform_input)\n",
    "        # Validate the model\n",
    "        epoch_valid_loss = validate(valid_dataloader, model, loss_function, device, master_bar, transform_common, transform_input)\n",
    "\n",
    "        # Save loss and acc for plotting\n",
    "        epoch_list.append(epoch + 1)\n",
    "        train_losses.append(epoch_train_loss)\n",
    "        valid_losses.append(epoch_valid_loss)\n",
    "\n",
    "        graphs = [[epoch_list, train_losses], [epoch_list, valid_losses]]\n",
    "        x_bounds = [1, num_epochs]\n",
    "\n",
    "        master_bar.write(\n",
    "            f\"Epoch {epoch + 1}, \"\n",
    "            f\"avg. train loss: {epoch_train_loss:.3f}, \"\n",
    "            f\"avg. valid. loss: {epoch_valid_loss:.3f}\"\n",
    "        )\n",
    "        master_bar.update_graph(graphs, x_bounds)\n",
    "\n",
    "\n",
    "    return train_losses, valid_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1716477392543,
     "user": {
      "displayName": "Tristan",
      "userId": "15709710985441936674"
     },
     "user_tz": -120
    },
    "id": "7djBzm896ATK"
   },
   "outputs": [],
   "source": [
    "class Autoencoder(nn.Module):\n",
    "\n",
    "    def __init__(self, image_size=64,num_channels=3, latent_dims=128, num_filters=32, do_sampling=False):\n",
    "        super(Autoencoder, self).__init__()\n",
    "\n",
    "        self.latent_dims  = latent_dims\n",
    "        self.image_size   = image_size\n",
    "        self.num_channels = num_channels\n",
    "        self.num_filters  = num_filters\n",
    "        self.do_sampling  = do_sampling\n",
    "\n",
    "        # Encoder\n",
    "        self.conv_encoder = nn.Sequential(\n",
    "            # TODO: Build the convolutional layers (torch.nn.Conv2d) here\n",
    "            torch.nn.Conv2d(self.num_channels, self.num_channels, (4,4), 2, 1),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Conv2d(self.num_channels,self.num_channels, (4,4), 2, 1),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Conv2d(self.num_channels,self.num_channels, (4,4), 2, 1),\n",
    "            torch.nn.ReLU(),\n",
    "        )\n",
    "\n",
    "        # Linear Encoder\n",
    "        # TODO: Match the dimensionality of the first and last layer here!\n",
    "        self.fc_lin_down = nn.Linear(64*self.num_filters, 8 * self.num_filters)\n",
    "        self.fc_mu       = nn.Linear(8 * self.num_filters, self.latent_dims)\n",
    "        self.fc_logvar   = nn.Linear(self.latent_dims, self.latent_dims)\n",
    "        self.fc_z        = nn.Linear(self.latent_dims, 8 * self.num_filters)\n",
    "        self.fc_lin_up   = nn.Linear(8 * self.num_filters, 64*self.num_filters)\n",
    "\n",
    "        # Decoder\n",
    "        self.conv_decoder = nn.Sequential(\n",
    "            # TODO: Implement the reverse of the encoder here using torch.nn.ConvTranspose2d layers\n",
    "            # The last activation here should be a sigmoid to keep the pixel values clipped in [0, 1)\n",
    "            torch.nn.Conv2d(self.num_channels, self.num_channels, (4,4), 2, 1),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Conv2d(self.num_channels,self.num_channels, (4,4), 2, 1),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Conv2d(self.num_channels,self.num_channels, (4,4), 2, 1),\n",
    "            nn.Sigmoid(),\n",
    "        )\n",
    "\n",
    "    def encode(self, x):\n",
    "        ''' Encoder: output is (mean, log(variance))'''\n",
    "        x       = self.conv_encoder(x)\n",
    "        # Here, we resize the convolutional output appropriately for a linear layer\n",
    "        # TODO: Fill in the correct dimensionality for the reordering\n",
    "        x       = x.view(-1, self.num_filters * 8 * 8)\n",
    "        x       = self.fc_lin_down(x)\n",
    "        x       = nn.functional.relu(x)\n",
    "        mu      = self.fc_mu(x)\n",
    "        logvar  = self.fc_logvar(x)\n",
    "        return mu, logvar\n",
    "\n",
    "    def sample(self, mu, logvar):\n",
    "        ''' Sample from Gaussian with mean `mu` and SD `sqrt(exp(logvarz))`'''\n",
    "        # Only use the full mean/stddev procedure if we want to later do sampling\n",
    "        # And only reparametrise if we are in training mode\n",
    "        if self.training and self.do_sampling:\n",
    "            std = torch.exp(logvar * 0.5)\n",
    "            eps = torch.randn_like(std)\n",
    "            sample = mu + (eps * std)\n",
    "            return sample\n",
    "        else:\n",
    "            return mu\n",
    "\n",
    "    def decode(self, z):\n",
    "        '''Decoder: produces reconstruction from sample of latent z'''\n",
    "        z = self.fc_z(z)\n",
    "        z = nn.functional.relu(z)\n",
    "        z = self.fc_lin_up(z)\n",
    "        z = nn.functional.relu(z)\n",
    "        # TODO: Fill in the correct dimensionality for the reordering here again\n",
    "        z = z.view(-1, self.num_filters, 8, 8)\n",
    "        z = self.conv_decoder(z)\n",
    "        return z\n",
    "\n",
    "    def forward(self, x):\n",
    "        mu, logvar = self.encode(x)\n",
    "        z = self.sample(mu, logvar)\n",
    "        x_hat = self.decode(z)\n",
    "        if self.do_sampling:\n",
    "            return x_hat, mu, logvar\n",
    "        else:\n",
    "            return x_hat, None, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "executionInfo": {
     "elapsed": 272,
     "status": "ok",
     "timestamp": 1716477394985,
     "user": {
      "displayName": "Tristan",
      "userId": "15709710985441936674"
     },
     "user_tz": -120
    },
    "id": "QTZOfcLu_bR1"
   },
   "outputs": [],
   "source": [
    "def autoencoder_loss(recon_x, x, mu=None, logvar=None):\n",
    "    mse_loss = torch.nn.functional.mse_loss(recon_x, x, reduction='sum') / x.size(dim=0)\n",
    "\n",
    "    if mu is not None and logvar is not None:\n",
    "        raise NotImplementedError(\"Looks like you still need to implement the KL divergence loss!\")\n",
    "    else:\n",
    "        return mse_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "executionInfo": {
     "elapsed": 259,
     "status": "ok",
     "timestamp": 1716477397033,
     "user": {
      "displayName": "Tristan",
      "userId": "15709710985441936674"
     },
     "user_tz": -120
    },
    "id": "B1AVTs0f_gFv"
   },
   "outputs": [],
   "source": [
    "model = Autoencoder()\n",
    "model = model.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 284,
     "status": "ok",
     "timestamp": 1716477399005,
     "user": {
      "displayName": "Tristan",
      "userId": "15709710985441936674"
     },
     "user_tz": -120
    },
    "id": "VJVZD4r7AAOl",
    "outputId": "d185d5b4-5a78-4c14-b226-f3bd69be8725"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Autoencoder(\n",
       "  (conv_encoder): Sequential(\n",
       "    (0): Conv2d(3, 3, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
       "    (1): ReLU()\n",
       "    (2): Conv2d(3, 3, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
       "    (3): ReLU()\n",
       "    (4): Conv2d(3, 3, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
       "    (5): ReLU()\n",
       "  )\n",
       "  (fc_lin_down): Linear(in_features=2048, out_features=256, bias=True)\n",
       "  (fc_mu): Linear(in_features=256, out_features=128, bias=True)\n",
       "  (fc_logvar): Linear(in_features=128, out_features=128, bias=True)\n",
       "  (fc_z): Linear(in_features=128, out_features=256, bias=True)\n",
       "  (fc_lin_up): Linear(in_features=256, out_features=2048, bias=True)\n",
       "  (conv_decoder): Sequential(\n",
       "    (0): Conv2d(3, 3, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
       "    (1): ReLU()\n",
       "    (2): Conv2d(3, 3, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
       "    (3): ReLU()\n",
       "    (4): Conv2d(3, 3, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
       "    (5): Sigmoid()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
